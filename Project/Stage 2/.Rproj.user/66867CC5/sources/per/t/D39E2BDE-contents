---
title: "ProjectStage2"
author: "Ian Donnellan"
date: '2022-08-01'
output: 
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    theme: united 
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r}
library(pROC)
library(plyr)
library(ROCR)
library(boot)
library(caret)
library(randomForest)
```

# A

The variables in the dataset do not have intuitive names (e.g., the meaning of S3 is unclear). Referencing the data description and the AER paper, identify the qualitative dependent that you will be modeling and the set of covariates that you intend to include in your various models, and rename the variables so that they have (somewhat) intuitive names. Be certain that the debt-to-income ratio and the race, self-employed, marital status, and education indicator variables are included, among other variables.

## Reading in data and formatting

```{r}
mortgage.data <- read.csv("C:/Users/Ian Ah/Documents/GitHub/ECO5445/Project/Data/hmda_sw.csv")

col_names = c("Sequence","Loan_Type","Loan_Purpose","Occupancy","Loan_Amount", 
             "Action_Taken","Location","County","Race", "Co_App_Race","Sex",
             "Co_App_Sex","App_Income","Loan_Purchaser","Reasons_For_Denial",
             "Reasons_Corr_1","Reasons_Corr_2","Reasons_Corr_3","Number_Units",
             "Marital_Status","Number_Dependents","Years_Employed",
             "Years_Employed_Job","Self_Employed","Base_Monthly_Income",
             "Base_Monthly_Income_Co_App","Total_Monthly_Income",
             "Total_Monthly_Income_Co_App","Prop_Monthly_Expense",
             "Purchase_Price","Other_Financing","Liquid_Assets",
             "Commercial_Credit_Report","Credit_History_Meets_Guidelines",
             "Consumer_Credit_Lines","Credit_History_Mortgage",
             "Credit_History_Consumer","Credit_History","Debt_to_Income_Housing",
             "Debt_to_Income_Total","Fixed_or_Adjustable_Loan","Term_of_Loan",
             "Special_Loan_Prog","Appraised_Value","Type_of_Property",
             "PMI_Sought?","PMI_Denied?","Gift_Grant_Downpayment?","Cosigner?",
             "Unverifiable_Info","Times_App_Reviewed","Net_Worth",
             "Prob_Unemployment","Minority_Population","Boarded_Up_Value",
             "Median_Income","Applicant_Age","Tract_Vacancy",
             "Years_of_Education","Change_in_Median_Value","Owner_Occupied_Dummy"
             ,"Type_of_Prop_Dummy")

colnames(mortgage.data) <- col_names


variables <- mortgage.data[c("Debt_to_Income_Total", "Race", "Self_Employed","Marital_Status","Years_of_Education","Loan_Amount","Appraised_Value","Action_Taken","Sex","Total_Monthly_Income","Purchase_Price","Credit_History","Years_Employed_Job")]

variables$Race <- factor(variables$Race, levels= c(3,5), labels = c(0,1))
variables$Action_Taken <- factor(variables$Action_Taken, levels = c(1,2,3), labels = c(1,1,0))
variables$Marital_Status <- factor(variables$Marital_Status)
variables$Sex <- factor(variables$Sex, levels= c(1,2), labels = c("Male","Female"))
variables$Self_Employed <- factor(variables$Self_Employed, levels= c(0,1), labels = c("Not Self-Employed","Self-Employed"))
variables$Debt_to_Income_Total <- variables$Debt_to_Income_Total/100

variables[variables == 999999.4] <- NA
var.omit <- na.omit(variables)
```

## Variables choosen description

Appraised value and Loan amount can be compared to find the equity in the property and lender's margin of safety. Higher the applicant's equity share the lower the chance of default. I included both these variables in planning of creating a interaction variable in the regression model to find the loan to value ratio. Credit History is important to lenders as the paper states as it is a way for them to see how applicants have previously met commitments in borrowings. I am including just the credit history available to public records as it shows if an individual has filed for bankruptcy previously which would hinder chances of being approved for a loan as lenders tend to view that as important. I did not include credit history for mortgage payments as I did not know if all applicants have had a mortgage previously and believe that the data may not be useful. Including if an applicant is self-employed or not is a way to determine job and income security. According to the paper self-employed individuals have higher income risk and it is more difficult to verify income as they could fluff up numbers if they desired. Being self-employed could lead to a higher denial rate due to those factors. I've also included the years of education of the applicants as more educated individuals have higher earnings potential which would lessen the risk of default. It also increases their ability to find work in the case of a layoff. I've included Sex as a way to determine if women are at a disadvantage when applying for a loan when compared to men. According to the paper sex, year employed in profession, and years of education are grouped together in determining the if an applicant may face a spell of unemployment. Debt-to-Income ratio is an important variable as individuals with a higher debt-to-income may have a higher chance of default as their free income will be much lower as the ratio increases. A higher debt-to-income ratio will increase the denial likelihood. The race of the applicant plays a big part in the study as it is hypothesized that minorities are more likely to be denied a loan when compared to a white individual with the same data. The marital status variable indicates the household income of an individual. Married individuals are more likely to have greater stability in household income according to the paper, thus leading to a higher chance of being approved. The action taken variable will be our response variable in our regression model as we are trying to determine if someone would be approved our denied based on the information they provided. I believe the variables choose will cover the financial, employment, education, and characteristics of individuals surveyed.   

# B

Generate summary statistics on the set of variables selected in A, and explain the composition of the sample and of the characteristics of an average (representative) applicant. In the process, you should also generate and histograms and frequency counts on particular variables of interest, which can be referenced in your explanation of the composition of the sample and of a representative applicant.

## Summary Statistics

```{r}
summary(var.omit)

sd(variables$Loan_Amount, na.rm = TRUE)
sd(variables$Appraised_Value, na.rm = TRUE)
sd(variables$Total_Monthly_Income, na.rm = TRUE)
sd(variables$Years_of_Education, na.rm = TRUE)
sd(variables$Purchase_Price, na.rm = TRUE)
sd(variables$Years_Employed_Job, na.rm = TRUE)
sd(variables$Debt_to_Income_Total, na.rm = TRUE)
```
## Histograms, Plots, and Counts

```{r}
par(mfrow=c(1,3))
plot(var.omit$Race,var.omit$Action_Taken, col = c("#146600","#20A000"), main = "Race to Approval or Denial", xlab = "Race Black(0) White(1)", ylab= "Approved(1) or Denied(0)")
plot(var.omit$Sex,var.omit$Action_Taken, col = c("#146600","#20A000"), main = "Sex to Approval or Denial", xlab = "Sex", ylab= "Approved(1) or Denied(0)")
plot(var.omit$Marital_Status,var.omit$Action_Taken,col = c("#146600","#20A000"), main = "Marital Status to Approval or Denial", xlab = "Married, Separated, or Un-Married", ylab= "Approved(1) or Denied(0)")
```

```{r}
par(mfrow=c(2,3))
hist(variables$Years_of_Education, breaks = "fd", main = "Years of Education", xlab = "Number of Years", col = "#B80000")
hist(variables$Appraised_Value, breaks = "fd",main = "Appraised Value", xlab = "Value in Thousands", col = "#B80000")
hist(variables$Loan_Amount, breaks = "fd", main = "Loan Amount", xlab = "Loan amount in thousands", col = "#B80000")
hist(variables$Debt_to_Income_Total, breaks = "fd", main = "Debt to Income Ratio", xlab = "Debt to Income Percent", col = "#B80000")
hist(variables$Years_Employed_Job, breaks = "fd", main = "Years Employed in Job", xlab = "Number of Years", col = "#B80000")
hist(variables$Total_Monthly_Income, breaks = "fd", main = "Monthly Income", xlab = "$ Income Per Month", col = "#B80000")
```

```{r}
count(variables, "Action_Taken")
count(variables, "Race")
count(variables, "Sex")
count(variables, "Marital_Status")
```

## Correlation Between Variables

```{r}
cor(var.omit$Years_of_Education, var.omit$Total_Monthly_Income)
cor(var.omit$Appraised_Value, var.omit$Loan_Amount)
cor(var.omit$Years_of_Education, var.omit$Years_Employed_Job)
```

## Composition of the Sample
Looking at the summary statistics of the variables chosen we can make many observations. With the N/A values removed from the dataset we get a clearer look at the counts a statistics of the sample. We can see it is made up of largely white males with white individuals accounting for 1,958 people and black accounting for 330. The males make up 1,818 individuals while females total 470. The majority of individuals are married making up 1,391 of the sample with the remaining 897 being un-married. The average person has a debt-to-income ratio of 33% which mean 33 cents to their dollar will go to expenses each month. The monthly income of individuals in the sample average 4,939 per month with 50% of individuals in the sample earning less than 3,602 per month. The standard deviation of monthly income is 5,162 due to the outliers seen in the histogram. The average loan amount of the sample is 140,000 with the purchase price average being 190,000. The standard deviation of the loan amount and purchase price is relatively high at 83,000 and 130,000 respectively. This is due to the large outliers in the max values in the data. The average individual has a college degree or 16 years of education. This also splits the data down the middle with 50% having higher education and the lower 50% having a high school degree or less. Self-employed individuals make up a small size of the sample with 269 people out of the over 2,200. These people have been in their line of work on average of ~7 years with a standard deviation of 6.59 years due to some long employed individuals increasing the spread. With all this in mind we can make up that the average applicant is a married white male with a college degree that is not self-employed earning around 5,000 per month looking to purchase a house appraised at 200,000 with a loan of 140,000. Out of all these applicants 2014 were approved and 274 were denied. 

I hypothesized that years of education and monthly income would be highly correlated due to college degree holders having higher earnings potential. I was surprised to find out the correlation was not very high at 0.24511. Appraised value and loan amount were highly correlated at .72825 which does not come at much of a surprise. The last variables I wanted to know the correlation of 

When observing the histograms of the data we can see that appraised value and loan amount are both skewed right. To help make the data more uniform I will be taking the log of those values and that should help with the distribution. This can also be seen with the Years Employed by Job which taking a log will also help. The large spread of the data in total monthly income can be reduced by taking the square root of the values. I will test these transformations when I cross validate my models to determine the best options.



# C

With the full sample, estimate the logistic regression model, where the deny/approve dummy variable is the response variable and the debt-to-income ratio and the race, self-employed, marital status, and education indicator variables are the co-variates. Graph the ROC curve and calculate the AUC. Also, compute the confusion matrix at alternative cut-off levels, and calculate the classifier sensitivity, specificity, the false-positive rate, the false-negative rate, the model accuracy and error rate to confirm they are the same as those produced by R. Provide a written explanation summarizing the findings.

## Regression Model

```{r}
Reg <- glm(Action_Taken ~ Debt_to_Income_Total + Race + Self_Employed + Marital_Status + Years_of_Education + Credit_History + Loan_Amount + Appraised_Value + Years_Employed_Job, data = variables ,family = "binomial")

summary(Reg)
```
## Regression Explanation
The regression equation shows that as debt to income ratio increases the chances of being denied also increase as it is a positive value. This can also be seen with being un-married, having a worse credit history, being self-employed, and a higher loan amount. The variables that make the approval chances improve are being white, having higher years of education, having a higher appraised value, and being employed in your job for a longer period of time.

## ROC and AUC

```{r}
prob <- predict(Reg, variables, type = "response")
my_roc <- roc(variables$Action_Taken ~ prob, plot = TRUE, print.auc = TRUE)
my_auc <- auc(my_roc)

logit.pred <- factor(prob > 0.5, levels = c(FALSE,TRUE),
                     labels = c("Approved","Denied"))
logit.perf <- table(variables$Action_Taken, logit.pred, dnn = c("Actual","Predicted"))
logit.perf

logit.pred2 <- factor(prob > 0.75, levels = c(FALSE,TRUE),
                     labels = c("Approved","Denied"))
logit.perf2 <- table(variables$Action_Taken, logit.pred2, dnn = c("Actual","Predicted"))
logit.perf2

logit.pred3 <- factor(prob > 0.25, levels = c(FALSE,TRUE),
                     labels = c("Approved","Denied"))
logit.perf3 <- table(variables$Action_Taken, logit.pred3, dnn = c("Actual","Predicted"))
logit.perf3

threshold <- my_roc$thresholds[which.max(my_roc$sensitivities + my_roc$specificities)]

logit.pred.thresh <- factor(prob > threshold, levels = c(FALSE,TRUE),
                     labels = c("Approved","Denied"))
logit.perf.thresh <- table(variables$Action_Taken, logit.pred.thresh, dnn = c("Actual","Predicted"))
logit.perf.thresh

```

## Performance of Model

```{r}
performance <- function(table, n = 4){
  if(!all(dim(table) == c(2,2)))
    stop("Must be a 2 x 2 table")
  tn = table[1,1]
  fp = table[1,2]
  fn = table[2,1]
  tp = table[2,2]
  sensitivity = tp/(tp+fn)
  specificity = tn/(tn+fp)
  ppp = tp/(tp+fp)
  npp = tn/(tn+fp)
  hitrate = (tp+tn)/(tp+tn+fp+fn)
  result <- paste0("Sensitivity = ", round(sensitivity,n),
                   "\nSpecificity = ",round(specificity,n),
                   "\nPositive Predictive Value = ", round(ppp,n),
                   "\nNegative Predictive Value = ", round(npp,n),
                   "\nAccuracy = ", round(hitrate,n))
  cat(result)
}

#0.5  
performance(logit.perf)
#0.75
performance(logit.perf2)
#0.25
performance(logit.perf3)
#Optimal Threshold
performance(logit.perf.thresh)
```

## ROC Explanation 

When calculating the ROC with the original model we get an area under the curve of 0.782. When computing the confusion matrix at the different threshold values the most accurate model is the model with a threshold of 0.5. That threshold leads to an accuracy of .8905 with the sensitivity being 0.1733 and specificity of 0.9882. The optimal threshold value is computed at 0.0997 which give the model an accuracy of 0.6965, a specificity of 0.6886 and a sensitivity of 0.7545.

# D

Next, using 10-fold cross validation, estimate a variety of logistic regression models and evaluate their predictive performance across a range of threshold values in each case. The models can (should) include interaction variables and polynomial terms (e.g., quadratic and cubic variables). Of interest is identifying the model and threshold value that yield the smallest average test misclassification rate; however, you can also calculate model accuracy and the AUC. Document in a table the performance of the various models using the chosen performance measures.

## 10-Fold Cross Validation

```{r}
#Original Model
set.seed(1234)
cv.housing <- cv.glm(data=var.omit, glmfit=Reg, K=10)

#New Model
Reg2 <- glm(Action_Taken ~ Debt_to_Income_Total + Race + Self_Employed + Marital_Status + Years_of_Education + Credit_History + log(Loan_Amount) + log(Appraised_Value) + Years_Employed_Job + Total_Monthly_Income, data = var.omit ,family = "binomial")

cv.housing2 <- cv.glm(data=var.omit, glmfit=Reg2, K=10)

#New Model
Reg3 <-  glm(Action_Taken ~ Debt_to_Income_Total + Race + Self_Employed + Marital_Status + Years_of_Education + Credit_History + Loan_Amount/Appraised_Value + Years_Employed_Job + sqrt(Total_Monthly_Income), data = var.omit ,family = "binomial")

cv.housing3 <- cv.glm(data=var.omit, glmfit=Reg3, K=10)

#New Model
Reg4 <-  glm(Action_Taken ~ sqrt(Debt_to_Income_Total) + Race + Self_Employed + Marital_Status + Years_of_Education + Credit_History + Loan_Amount/Appraised_Value, data = var.omit ,family = "binomial")

cv.housing4 <- cv.glm(data=var.omit, glmfit=Reg4, K=10)

#New Model
Reg5 <-  glm(Action_Taken ~ sqrt(Debt_to_Income_Total) + Race + Self_Employed + Marital_Status + Years_of_Education + Credit_History + log(Loan_Amount/Appraised_Value) + Sex + Years_Employed_Job, data = var.omit ,family = "binomial")

cv.housing5 <- cv.glm(data=var.omit, glmfit=Reg5, K=10)

#MSEs of Models
cv.housing$delta[2]
cv.housing2$delta[2]
cv.housing3$delta[2]
cv.housing4$delta[2]
cv.housing5$delta[2]
```

## AUC of New Models

```{r}
set.seed(1234)
prob2 <- predict(Reg2, var.omit, type = "response")
my_roc2 <- roc(var.omit$Action_Taken ~ prob2, plot = TRUE, print.auc = TRUE)
threshold2 <- my_roc2$thresholds[which.max(my_roc2$sensitivities + my_roc2$specificities)]

prob3 <- predict(Reg3, var.omit, type = "response")
my_roc3 <- roc(var.omit$Action_Taken ~ prob3, plot = TRUE, print.auc = TRUE)
threshold3 <- my_roc3$thresholds[which.max(my_roc3$sensitivities + my_roc3$specificities)]

prob4 <- predict(Reg4, var.omit, type = "response")
my_roc4 <- roc(var.omit$Action_Taken ~ prob4, plot = TRUE, print.auc = TRUE)
threshold4 <- my_roc4$thresholds[which.max(my_roc4$sensitivities + my_roc4$specificities)]

prob5 <- predict(Reg5, var.omit, type = "response")
my_roc5 <- roc(var.omit$Action_Taken ~ prob5, plot = TRUE, print.auc = TRUE)
threshold5 <- my_roc5$thresholds[which.max(my_roc5$sensitivities + my_roc5$specificities)]

logit.pred.thresh2 <- factor(prob2 > threshold2, levels = c(FALSE,TRUE),
                     labels = c("Approved","Denied"))
logit.perf.thresh2 <- table(var.omit$Action_Taken, logit.pred.thresh2, dnn = c("Actual","Predicted"))
logit.perf.thresh2

logit.pred.thresh3 <- factor(prob3 > threshold, levels = c(FALSE,TRUE),
                     labels = c("Approved","Denied"))
logit.perf.thresh3 <- table(var.omit$Action_Taken, logit.pred.thresh3, dnn = c("Actual","Predicted"))
logit.perf.thresh3

logit.pred.thresh4 <- factor(prob4 > threshold, levels = c(FALSE,TRUE),
                     labels = c("Approved","Denied"))
logit.perf.thresh4 <- table(var.omit$Action_Taken, logit.pred.thresh4, dnn = c("Actual","Predicted"))
logit.perf.thresh4

logit.pred.thresh5 <- factor(prob5 > threshold, levels = c(FALSE,TRUE),
                     labels = c("Approved","Denied"))
logit.perf.thresh5 <- table(var.omit$Action_Taken, logit.pred.thresh5, dnn = c("Actual","Predicted"))
logit.perf.thresh5

performance(logit.perf.thresh2)
performance(logit.perf.thresh3)
performance(logit.perf.thresh4)
performance(logit.perf.thresh5)
```

## Evaluating Results

```{r}
set.seed(1234)
cv.housing$delta[2]
cv.housing2$delta[2]
cv.housing3$delta[2]
cv.housing4$delta[2]
cv.housing5$delta[2]

my_roc$auc
my_roc2$auc
my_roc3$auc
my_roc4$auc
my_roc5$auc
```

# E

Of the competing models that you estimated and thresholds that you evaluated, identify the superior model for classification purposes. Re-estimate the model with the full sample of data. Then, graph the ROC, calculate the AUC, and compute the confusion matrix at the threshold level associated with the minimum average test mis-classification rate . Calculate the classifier sensitivity and specificity, the false-positive rate, the false negative rate, the accuracy, and overall mis-classification rate. How well does your superior model perform relative to the model estimated in C? Explain. Note that to do so you will need to calculate the confusion matrix from the estimated model in C at the threshold level.

## Superior Model

```{r}
Reg2 <- glm(Action_Taken ~ Debt_to_Income_Total + Race + Self_Employed + Marital_Status + Years_of_Education + Credit_History + log(Loan_Amount) + log(Appraised_Value) + Years_Employed_Job + Total_Monthly_Income, data = var.omit ,family = "binomial")
```

In the superior model I decided to log both the loan amount and appraised value variables as they were both skewed right. This made the data much more uniform. I also added Year employed by job and the total monthly income of applicants as this will add more accuracy to the prediction.

### ROC Graph and AUC

```{r}
prob2 <- predict(Reg2, var.omit, type = "response")
my_roc2 <- roc(var.omit$Action_Taken ~ prob2, plot = TRUE, print.auc = TRUE)
threshold2 <- my_roc2$thresholds[which.max(my_roc2$sensitivities + my_roc2$specificities)]
```


### Confusion Matrix at Optimal Level

```{r}
logit.pred.thresh2 <- factor(prob2 > threshold2, levels = c(FALSE,TRUE),
                     labels = c("Approved","Denied"))
logit.perf.thresh2 <- table(var.omit$Action_Taken, logit.pred.thresh2, dnn = c("Actual","Predicted"))
logit.perf.thresh2
```

### Performance Measures

```{r}
performance(logit.perf.thresh2)
```

## Original Model

```{r}
Reg <- glm(Action_Taken ~ Debt_to_Income_Total + Race + Self_Employed + Marital_Status + Years_of_Education + Credit_History + Loan_Amount + Appraised_Value + Years_Employed_Job, data = variables ,family = "binomial")
```

### ROC Graph and AUC

```{r}
prob <- predict(Reg, variables, type = "response")
my_roc <- roc(variables$Action_Taken ~ prob, plot = TRUE, print.auc = TRUE)
my_auc <- auc(my_roc)
```

### Confusion Matrix at Optimal Level

```{r}
logit.pred.threshOG <- factor(prob > threshold2, levels = c(FALSE,TRUE),
                     labels = c("Approved","Denied"))
logit.perf.threshOG <- table(variables$Action_Taken, logit.pred.thresh, dnn = c("Actual","Predicted"))
logit.perf.threshOG
```

### Performance Measures

```{r}
performance(logit.perf.threshOG)
```

Of the 5 regression models tested the one that has the best performance would be the second model tested or Reg2. The MSE of the model is the lowest at 0.08791 outperforming by the original regression equation with an MSE of 0.0883. It also outperforms the original model with an AUC of 0.7877. The accuracy of this model at the optimal threshold value is 0.8164, sensitivity is 0.6022, and specificity of 0.8456. Comparing that to the original model at the same threshold level we get an accuracy of 0.8152, a sensitivity of 0.5848, and a Specificity of 0.8465. The new model out performs the old in all categories. 



